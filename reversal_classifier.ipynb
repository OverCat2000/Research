{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ca3ea6b3-40f6-478b-a04e-7df824ce0d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from pyts.image import GramianAngularField\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3fe0cf69-c072-45b6-b1eb-9b54805d8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgDataLoader():\n",
    "    DATABASE_URL = \"postgresql://overcat:overmind@localhost:5432/stocks\"\n",
    "    query = \"\"\"\n",
    "    SELECT * from data.reversals;\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = []\n",
    "    labels = []\n",
    "    \n",
    "    try:\n",
    "        conn = psycopg2.connect(DATABASE_URL)\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            results = cur.fetchall()  # Fetch all rows from the query result\n",
    "            \n",
    "            for row in results:\n",
    "                matrix1 = np.array([\n",
    "                    row[1][\"Open\"],\n",
    "                    row[1][\"High\"],\n",
    "                    row[1][\"Low\"],\n",
    "                    row[1][\"Close\"],\n",
    "                    row[1][\"Volume\"]\n",
    "                    # row[1][\"Time\"]\n",
    "                ])\n",
    "    \n",
    "                matrix2 = np.array([\n",
    "                    row[2][\"Open\"],\n",
    "                    row[2][\"High\"],\n",
    "                    row[2][\"Low\"],\n",
    "                    row[2][\"Close\"],\n",
    "                    row[2][\"Volume\"]\n",
    "                    # row[2][\"Time\"]\n",
    "                ])\n",
    "    \n",
    "                # print(row[3], row[4])\n",
    "                # fig, axes = plt.subplots(1, 1)\n",
    "                # candle(np.concatenate((matrix1, matrix2), axis=1), ax=axes, t0=row[4])\n",
    "    \n",
    "                matrix1 = np.moveaxis(matrix1, 1, 0)\n",
    "                matrix2 = np.moveaxis(matrix2, 1, 0)\n",
    "    \n",
    "                # fig, axes = plt.subplots(1, 1)\n",
    "                # candle(np.moveaxis(np.concatenate((matrix1, matrix2)), 1, 0), ax=axes, t0=temp[0])\n",
    "                dataset.append(matrix1)\n",
    "                labels.append(row[5])\n",
    "    finally:\n",
    "        conn.close()\n",
    "        \n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "73c7ee45-024f-496a-9d54-2dcdc49f5a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gasf = GramianAngularField(method=\"summation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ac331467-8b7a-46e6-8edf-1177db13659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1355, 1355)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = pgDataLoader()\n",
    "len(data), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0915eebd-a272-41b4-8b96-34f5d4262a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_data = []\n",
    "for i, sample in enumerate(data):\n",
    "    open_prices = sample[:, 0]\n",
    "    high_prices = sample[:, 1]\n",
    "    low_prices = sample[:, 2]\n",
    "    close_prices = sample[:, 3]\n",
    "    volume = sample[:, 4]\n",
    "\n",
    "    body_length = np.abs(close_prices - open_prices)\n",
    "    upper_shadow_length = high_prices - np.maximum(open_prices, close_prices)\n",
    "    lower_shadow_length = np.minimum(open_prices, close_prices) - low_prices\n",
    "\n",
    "    alt_sample = np.moveaxis(np.vstack((body_length, upper_shadow_length, lower_shadow_length, close_prices, volume)), 1, 0)\n",
    "    # alt_sample = np.moveaxis(np.vstack((body_length, upper_shadow_length, lower_shadow_length, close_prices)), 1, 0)\n",
    "    # alt_sample = np.moveaxis(np.vstack((body_length, upper_shadow_length, lower_shadow_length)), 1, 0)\n",
    "\n",
    "    alt_data.append(alt_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b4ddaedc-41b5-40a3-909e-6d4c64d6ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, gasf_transform=None):\n",
    "        self.sequences = data\n",
    "        self.labels = labels\n",
    "        self.gasf_transform = gasf_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.gasf_transform:\n",
    "            gasf_images = np.array(self.gasf_transform.transform(np.moveaxis(self.sequences[idx], 1, 0)))\n",
    "            # return torch.unsqueeze(torch.tensor(gasf_images, dtype=torch.float32), dim=0), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            return torch.tensor(gasf_images, dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        else:\n",
    "            return torch.unsqueeze(torch.tensor(self.sequences[idx], dtype=torch.float32), dim=0), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        # return torch.tensor(self.sequences[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ff95c1a5-fec5-46b0-bb13-d9d1b5f7f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(0.8*len(data))\n",
    "# test_size = len(data) - train_size\n",
    "# dataset = CustomDataset(data, labels)\n",
    "\n",
    "train_size = int(0.999*len(alt_data))\n",
    "test_size = len(alt_data) - train_size\n",
    "dataset = CustomDataset(alt_data, labels, gasf)\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "48c20ecb-3696-4143-b5cb-2f28dab4ac7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(5, 5))\n",
    "axes = axes.flatten()\n",
    "# for idx, img in enumerate(next(iter(train_dataloader))[0][0][0]):\n",
    "for idx, img in enumerate(next(iter(train_dataloader))[0][0]):\n",
    "    axes[idx].matshow(img)\n",
    "    axes[idx].set_xticks([])  \n",
    "    axes[idx].set_yticks([])  \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "76f0db7e-203f-4de1-b20f-cbbfe7419261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 8, 16, 16]), torch.Size([32, 5, 16, 16]))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = next(iter(train_dataloader))[0]\n",
    "# c1 = nn.Conv1d(in_channels=4, out_channels=1, kernel_size=3, stride=1)\n",
    "# c1(temp.permute(0, 2, 1))\n",
    "c1 = nn.Conv2d(in_channels=5, out_channels=8, kernel_size=3, padding=1)\n",
    "c1(temp).shape, temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "1e9551c2-c8fc-46ba-9034-aad143552bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMClassifier(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, num_classes, filters):\n",
    "#         super(LSTMClassifier, self).__init__()\n",
    "#         self.c1 = nn.Conv1d(in_channels=input_size, out_channels=filters, kernel_size=2, stride=1)\n",
    "#         self.lstm = nn.LSTM(filters, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "#         self.hidden_size = hidden_size\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.c1(x.permute(0, 2, 1))\n",
    "#         x = torch.tanh(x)\n",
    "\n",
    "#         h0 = torch.zeros(num_layers*2, x.size(0), self.hidden_size).to(x.device)\n",
    "#         c0 = torch.zeros(num_layers*2, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "#         out, _ = self.lstm(x.permute(0, 2, 1), (h0, c0))\n",
    "#         # out = self.flatten(out)\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         # out = self.fc(out)\n",
    "        \n",
    "#         return out\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, filters):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=5, out_channels=20, kernel_size=3, padding=1)\n",
    "        self.c2 = nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.dropout1 = nn.Dropout(p=0.4)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.bn1 = nn.BatchNorm2d(10)\n",
    "        self.bn2 = nn.BatchNorm2d(10)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=40, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=0.4, )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x.reshape(-1, 256, 40)\n",
    "\n",
    "        h0 = torch.zeros(num_layers*2, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(num_layers*2, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # out, _ = self.lstm(x.permute(0, 2, 1), (h0, c0))\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # out = self.flatten(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ed90c19e-1ac4-4fab-ad5f-dcd6b27a1c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifier(\n",
       "  (c1): Conv2d(5, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c2): Conv2d(20, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
       "  (dropout1): Dropout(p=0.4, inplace=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lstm): LSTM(40, 32, num_layers=4, batch_first=True, dropout=0.4, bidirectional=True)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 32\n",
    "num_layers = 4\n",
    "num_classes = 2\n",
    "\n",
    "model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes, filters)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "03a6a13f-2e71-4c5f-937d-6ac151053595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(next(iter(train_dataloader))[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ff599b89-3109-4c5a-bef5-ab82e6ca3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryAccuracy:\n",
    "    def __init__(self, threshold=0.5):\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, logits, targets):\n",
    "        # Apply sigmoid to logits to get probabilities\n",
    "        probabilities = torch.sigmoid(logits).squeeze(dim=1)\n",
    "        # Convert probabilities to binary predictions\n",
    "        predictions = (probabilities >= self.threshold).float()\n",
    "        # Compare predictions with targets and calculate accuracy\n",
    "        correct = (predictions == targets).float().sum()\n",
    "        accuracy = correct / targets.numel()\n",
    "        return accuracy.item()\n",
    "\n",
    "class MultiClassAccuracy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, logits, targets):\n",
    "        # Apply softmax to logits to get class probabilities (optional, for insight)\n",
    "        # probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "        # Get the predicted class indices by applying argmax to logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Compare predictions with targets and calculate accuracy\n",
    "        correct = (predictions == targets).float().sum()\n",
    "        accuracy = correct / targets.numel()  # Total number of samples\n",
    "        return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5f5202a9-7bbe-415e-8f7b-d0649e6b5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "accuracy_fn = MultiClassAccuracy()\n",
    "# accuracy_fn = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a54e50c2-5f8e-4264-aeb8-dd5119db3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # Loop through data loader data batches\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 1. Forward pass\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # print(X.shape)\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # print(y_pred)\n",
    "        # print()\n",
    "        # print(y)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred.squeeze(1), y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        train_acc += accuracy_fn(y_pred, y)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "4692b420-0c1c-4a6d-9790-d7c63aada1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits.squeeze(1), y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate and accumulate accuracy\n",
    "            test_acc += accuracy_fn(test_pred_logits, y)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa45f7-eab5-4e7c-8706-676c196b0983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "11798971-37ff-4b95-9203-9bea26197884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int = 5):\n",
    "\n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "\n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f2dae77a-3ca0-48f9-a86f-3f28d060386c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c914b931f8094e469893e3890a88ce11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.6930 | train_acc: 0.5173 | test_loss: 0.6936 | test_acc: 0.5000\n",
      "Epoch: 2 | train_loss: 0.6552 | train_acc: 0.6409 | test_loss: 0.8786 | test_acc: 0.5000\n",
      "Epoch: 3 | train_loss: 0.5746 | train_acc: 0.7089 | test_loss: 0.6117 | test_acc: 0.5000\n",
      "Epoch: 4 | train_loss: 0.5551 | train_acc: 0.7325 | test_loss: 0.8774 | test_acc: 0.5000\n",
      "Epoch: 5 | train_loss: 0.5384 | train_acc: 0.7318 | test_loss: 0.5209 | test_acc: 0.5000\n",
      "Epoch: 6 | train_loss: 0.5165 | train_acc: 0.7612 | test_loss: 0.4329 | test_acc: 1.0000\n",
      "Epoch: 7 | train_loss: 0.5061 | train_acc: 0.7713 | test_loss: 0.3435 | test_acc: 1.0000\n",
      "Epoch: 8 | train_loss: 0.5074 | train_acc: 0.7594 | test_loss: 0.2676 | test_acc: 1.0000\n",
      "Epoch: 9 | train_loss: 0.4821 | train_acc: 0.7743 | test_loss: 0.3352 | test_acc: 1.0000\n",
      "Epoch: 10 | train_loss: 0.4825 | train_acc: 0.7833 | test_loss: 0.2867 | test_acc: 1.0000\n",
      "Epoch: 11 | train_loss: 0.4748 | train_acc: 0.7720 | test_loss: 0.1832 | test_acc: 1.0000\n",
      "Epoch: 12 | train_loss: 0.4511 | train_acc: 0.7936 | test_loss: 0.1495 | test_acc: 1.0000\n",
      "Epoch: 13 | train_loss: 0.4375 | train_acc: 0.8056 | test_loss: 0.1119 | test_acc: 1.0000\n",
      "Epoch: 14 | train_loss: 0.4313 | train_acc: 0.8052 | test_loss: 0.1198 | test_acc: 1.0000\n",
      "Epoch: 15 | train_loss: 0.4341 | train_acc: 0.7990 | test_loss: 0.1661 | test_acc: 1.0000\n",
      "Epoch: 16 | train_loss: 0.4481 | train_acc: 0.7898 | test_loss: 0.1504 | test_acc: 1.0000\n",
      "Epoch: 17 | train_loss: 0.4225 | train_acc: 0.8171 | test_loss: 0.1200 | test_acc: 1.0000\n",
      "Epoch: 18 | train_loss: 0.4217 | train_acc: 0.8052 | test_loss: 0.1016 | test_acc: 1.0000\n",
      "Epoch: 19 | train_loss: 0.4024 | train_acc: 0.8321 | test_loss: 0.1658 | test_acc: 1.0000\n",
      "Epoch: 20 | train_loss: 0.4156 | train_acc: 0.8263 | test_loss: 0.1560 | test_acc: 1.0000\n",
      "Epoch: 21 | train_loss: 0.4120 | train_acc: 0.8186 | test_loss: 0.1115 | test_acc: 1.0000\n",
      "Epoch: 22 | train_loss: 0.4239 | train_acc: 0.8168 | test_loss: 0.1148 | test_acc: 1.0000\n",
      "Epoch: 23 | train_loss: 0.3871 | train_acc: 0.8346 | test_loss: 0.1144 | test_acc: 1.0000\n",
      "Epoch: 24 | train_loss: 0.3735 | train_acc: 0.8492 | test_loss: 0.1273 | test_acc: 1.0000\n",
      "Epoch: 25 | train_loss: 0.3879 | train_acc: 0.8266 | test_loss: 0.0880 | test_acc: 1.0000\n",
      "Epoch: 26 | train_loss: 0.3778 | train_acc: 0.8459 | test_loss: 0.0864 | test_acc: 1.0000\n",
      "Epoch: 27 | train_loss: 0.3728 | train_acc: 0.8423 | test_loss: 0.1090 | test_acc: 1.0000\n",
      "Epoch: 28 | train_loss: 0.3763 | train_acc: 0.8396 | test_loss: 0.2279 | test_acc: 1.0000\n",
      "Epoch: 29 | train_loss: 0.3630 | train_acc: 0.8458 | test_loss: 0.1214 | test_acc: 1.0000\n",
      "Epoch: 30 | train_loss: 0.3514 | train_acc: 0.8480 | test_loss: 0.1295 | test_acc: 1.0000\n",
      "Epoch: 31 | train_loss: 0.3710 | train_acc: 0.8463 | test_loss: 0.1440 | test_acc: 1.0000\n",
      "Epoch: 32 | train_loss: 0.3617 | train_acc: 0.8481 | test_loss: 0.1280 | test_acc: 1.0000\n",
      "Epoch: 33 | train_loss: 0.3452 | train_acc: 0.8557 | test_loss: 0.1243 | test_acc: 1.0000\n",
      "Epoch: 34 | train_loss: 0.3367 | train_acc: 0.8502 | test_loss: 0.1629 | test_acc: 1.0000\n",
      "Epoch: 35 | train_loss: 0.3519 | train_acc: 0.8418 | test_loss: 0.0859 | test_acc: 1.0000\n",
      "Epoch: 36 | train_loss: 0.3261 | train_acc: 0.8605 | test_loss: 0.1543 | test_acc: 1.0000\n",
      "Epoch: 37 | train_loss: 0.3101 | train_acc: 0.8752 | test_loss: 0.0822 | test_acc: 1.0000\n",
      "Epoch: 38 | train_loss: 0.3342 | train_acc: 0.8695 | test_loss: 0.2764 | test_acc: 1.0000\n",
      "Epoch: 39 | train_loss: 0.3160 | train_acc: 0.8608 | test_loss: 0.2024 | test_acc: 1.0000\n",
      "Epoch: 40 | train_loss: 0.3192 | train_acc: 0.8581 | test_loss: 0.1435 | test_acc: 1.0000\n",
      "Epoch: 41 | train_loss: 0.3121 | train_acc: 0.8716 | test_loss: 0.1135 | test_acc: 1.0000\n",
      "Epoch: 42 | train_loss: 0.3226 | train_acc: 0.8685 | test_loss: 0.3008 | test_acc: 1.0000\n",
      "Epoch: 43 | train_loss: 0.2914 | train_acc: 0.8819 | test_loss: 0.0927 | test_acc: 1.0000\n",
      "Epoch: 44 | train_loss: 0.2936 | train_acc: 0.8756 | test_loss: 0.3416 | test_acc: 1.0000\n",
      "Epoch: 45 | train_loss: 0.3013 | train_acc: 0.8800 | test_loss: 0.1984 | test_acc: 1.0000\n",
      "Epoch: 46 | train_loss: 0.3014 | train_acc: 0.8790 | test_loss: 0.1247 | test_acc: 1.0000\n",
      "Epoch: 47 | train_loss: 0.2643 | train_acc: 0.8807 | test_loss: 0.0922 | test_acc: 1.0000\n",
      "Epoch: 48 | train_loss: 0.2765 | train_acc: 0.8877 | test_loss: 0.2803 | test_acc: 1.0000\n",
      "Epoch: 49 | train_loss: 0.2910 | train_acc: 0.8866 | test_loss: 0.2938 | test_acc: 1.0000\n",
      "Epoch: 50 | train_loss: 0.2861 | train_acc: 0.8874 | test_loss: 0.1899 | test_acc: 1.0000\n",
      "Epoch: 51 | train_loss: 0.2765 | train_acc: 0.8865 | test_loss: 0.2441 | test_acc: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[257], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Train model_0\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model_0_results \u001b[38;5;241m=\u001b[39m train(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     13\u001b[0m                         train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m     14\u001b[0m                         test_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m     15\u001b[0m                         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     16\u001b[0m                         loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m     17\u001b[0m                         epochs\u001b[38;5;241m=\u001b[39mNUM_EPOCHS)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# End the timer and print out how long it took\u001b[39;00m\n\u001b[1;32m     20\u001b[0m end_time \u001b[38;5;241m=\u001b[39m timer()\n",
      "Cell \u001b[0;32mIn[256], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 3. Loop through training and testing steps for a number of epochs\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[0;32m---> 17\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m                                        dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m     19\u001b[0m                                        loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[1;32m     20\u001b[0m                                        optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n\u001b[1;32m     21\u001b[0m     test_loss, test_acc \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     22\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader,\n\u001b[1;32m     23\u001b[0m         loss_fn\u001b[38;5;241m=\u001b[39mloss_fn)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# 4. Print out what's happening\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[254], line 18\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(X.shape)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(y_pred)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print()\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(y)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 2. Calculate  and accumulate loss\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[247], line 53\u001b[0m, in \u001b[0;36mLSTMClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(num_layers\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# out, _ = self.lstm(x.permute(0, 2, 1), (h0, c0))\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x, (h0, c0))\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# out = self.flatten(out)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1125\u001b[0m         hx,\n\u001b[1;32m   1126\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights,\n\u001b[1;32m   1127\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1128\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[1;32m   1130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m   1131\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[1;32m   1133\u001b[0m     )\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1137\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1145\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Start the timer\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "# Train model_0\n",
    "model_0_results = train(model=model,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c430feaa-6213-410b-9757-064b4e9e9974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"lstm_model.pth\")\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083f34bb-bb7f-44a6-ac3b-e31bc58d9a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10266b73-86d1-42a5-aed8-7ceb994cfed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169d9ef-ceef-4efb-b121-8d1f8968f92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
